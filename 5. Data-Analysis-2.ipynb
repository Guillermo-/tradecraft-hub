{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import pandas\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mask the dataset creation for educational purposes (viewer: do not open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = datasets.make_classification(n_samples=1000,                                                                    n_features=5, n_classes=2, n_informative=3, n_redundant=0, n_repeated=0, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pandas.DataFrame(data, columns=['comms', 'remote access', 'weather', 'external partners', 'physical access'])\n",
    "\n",
    "df_labels = pandas.DataFrame(labels, columns=['go/no-go criterion']) # go=0, no-go=1\n",
    "dataset = pandas.concat([df_data, df_labels], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important concepts we'll see below is the notion of dataset evolution. One of the most fundamental assumptions in applying machine learning within the operational environment is that the data used to train the model and the data we'll expose the model to in operations come from the same probability distribution. In other words, we assume the battlefield will look exactly as we trained to...\n",
    "\n",
    "We've simulated adding more examples and notice our model improved its accuracy despite having more decision complexity. The point of that was to show that more data can help you model's performance. What we'll see below is a change in distributions compared to the previous dataset. The point of this is to show that your real-world events distributions can change and so you must know when your model is becoming obsolete. In the field of ML this concern is called \"concept drift.\" [1](https://www-ai.cs.tu-dortmund.de/LEHRE/FACHPROJEKT/SS12/paper/concept-drift/tsymbal2004.pdf) | [2](https://machinelearningmastery.com/gentle-introduction-concept-drift-machine-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Cumulative Distribution\n",
    "\n",
    "[ECDF reference](https://towardsdatascience.com/what-why-and-how-to-read-empirical-cdf-123e2b922480) |\n",
    "[ECDF reference](https://machinelearningmastery.com/empirical-distribution-function-in-python/) |\n",
    "[Seaborn ecdfplot() reference](https://seaborn.pydata.org/generated/seaborn.ecdfplot.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in [*df_data]:  # unpack the column names in df_data via [*]\n",
    "    axes = seaborn.ecdfplot(df_data[feature])\n",
    "    axes.grid(True)\n",
    "\n",
    "# set the plot's label\n",
    "axes.set_xlabel('Feature Values', fontsize=10)\n",
    "# set plot's legend labels\n",
    "axes.legend([*df_data], fontsize=10)\n",
    "# set plot's title\n",
    "axes.set_title('Feature Analysis | Empirical Cumulative Distribution', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Density Estimation\n",
    "\n",
    "`Change the parameter bw_adjust to see its effect on the distribution` </br>\n",
    "[Seaborn kdeplot() reference](https://seaborn.pydata.org/generated/seaborn.kdeplot.html?highlight=kdeplot#seaborn.kdeplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in [*df_data]:  # unpack the column names in df_data via [*]\n",
    "    axes = seaborn.kdeplot(df_data[feature], bw_adjust=1.0)  # bw_adjust is defaulted to 1.0\n",
    "    axes.grid(True)\n",
    "\n",
    "# set the plot's label\n",
    "axes.set_xlabel('Feature Values', fontsize=10)\n",
    "# set plot's legend labels\n",
    "axes.legend([*df_data], fontsize=10)\n",
    "# set plot's title\n",
    "axes.set_title('Feature Analysis | Kernel Density Estimation', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Density Estimation Pair Plot\n",
    "\n",
    "Which feature would you consider to be noise? Which features would you consider informative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairgrid = seaborn.pairplot(dataset, kind='kde', hue='go/no-go criterion', aspect=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing the Kernel Density Estimation (KDE) of all the observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_row in range(0, 100): # range is done based on the amount of observations (i.e. rows) we have in our dataset\n",
    "    axes = seaborn.kdeplot(df_data.iloc[data_row], bw_adjust=1.0)\n",
    "    axes.set_xlabel('past events')\n",
    "    axes.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with the bandwidth to smooth or un-smooth the distributions :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_row in range(0, 100): # range is done based on the amount of observations (i.e. rows) we have in our dataset\n",
    "    axes = seaborn.kdeplot(df_data.iloc[data_row], bw_adjust=7.0)\n",
    "    axes.set_xlabel('past events')\n",
    "    axes.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For funzies I few the ECD of the observations. This chart tell me nothing. Ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in range(0, 100):  # range is done based on the amount of observations (i.e. rows) we have in our dataset\n",
    "    axes = seaborn.ecdfplot(df_data.iloc[sample])\n",
    "    axes.set_xlabel('past events')\n",
    "    axes.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
