{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acknowledged-knife",
   "metadata": {},
   "source": [
    "# This dataset is 10x larger than in Decision-Trees-1 (i.e. 1k samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-photograph",
   "metadata": {},
   "source": [
    "#### Mask the dataset creation for educational purposes (viewer: do not open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-symposium",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data, labels = datasets.make_classification(n_samples=1000, n_features=5, n_classes=2, n_informative=3, n_redundant=0, n_repeated=0, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-cancellation",
   "metadata": {},
   "source": [
    "#### Frame the data with features names for educational purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pandas.DataFrame(data, columns=['comms', 'remote access', 'weather', 'external partners', 'physical access'])\n",
    "df_labels = pandas.DataFrame(labels, columns=['go/no-go criterion']) # go=0, no-go=1\n",
    "dataset = pandas.concat([df_data, df_labels], axis=1)  # put observations and label data together\n",
    "# dataset.head()  # view some of the data for sanity check\n",
    "\n",
    "data_train, data_test, labels_train, labels_test = model_selection.train_test_split(df_data, df_labels, test_size=0.2, random_state=7)\n",
    "\n",
    "my_decision_tree = DecisionTreeClassifier(criterion='entropy', random_state=7)\n",
    "\n",
    "my_decision_tree.fit(X=data_train, y=labels_train)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "tree.plot_tree(my_decision_tree, feature_names=data_train.columns, class_names=['go', 'no-go'], filled=True, proportion=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-sense",
   "metadata": {},
   "source": [
    "# Comments on Decision Tree Above\n",
    "\n",
    "Wow. We see there is a more complex decision process now that we've included more data! As mentioned before, we could employ some pruning techniques where we remove some nodes to make this model less complex. Through this process we find configurations that will improve the model's performance.\n",
    "\n",
    "Speaking of performance, what is the current model's accuracy given more data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuracy = my_decision_tree.score(X=data_test, y=labels_test)\n",
    "print('Average Accuracy: {}%'.format(avg_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-frequency",
   "metadata": {},
   "source": [
    "#### We find that simply more data has improved our model's accuracy. We love our data! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(my_decision_tree, X=data_test, y_true=labels_test, display_labels=['go', 'no-go'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-greene",
   "metadata": {},
   "source": [
    "#### We see that we still have issues with classifying a \"go\" status. Notably, in our last model we had 0 issues with \"no-go\" status, but in this model, and given more data, it seems we have encouter some confusions, thus misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(my_decision_tree, X=data_test, y_true=labels_test, display_labels=['go', 'no-go'], normalize='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-shoot",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "black-magnet",
   "metadata": {},
   "source": [
    "# Feature to Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "def plot_importance(estimator, xtrain, ytrain, title, font_size=16, features=None):\n",
    "    results = permutation_importance(estimator, xtrain, ytrain, random_state=7)\n",
    "    axx = pandas.DataFrame(results['importances_mean']).T.plot(grid=True, kind='bar')\n",
    "    axx.legend(features, fontsize=font_size)\n",
    "    axx.set_title(title, fontsize=font_size)\n",
    "    axx.set_xlabel('features', fontsize=font_size)\n",
    "    axx.set_ylabel('score', fontsize=font_size)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plot_importance(my_decision_tree, data_train, labels_train, title='Decision Tree | Feature Importance', features=data_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-bundle",
   "metadata": {},
   "source": [
    "#### What we see up here is one of the most important concepts to rememebr. As we'll see in the data-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_train = data_train.drop(columns=['weather', 'external partners'])\n",
    "new_data_test = data_test.drop(columns=['weather', 'external partners'])\n",
    "new_labels_train = labels_train  # For sake of completeness we'll just copy it over to new variables\n",
    "new_labels_test = labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the columns are dropped\n",
    "new_data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tree = DecisionTreeClassifier(criterion='entropy', random_state=7)\n",
    "new_tree.fit(X=new_data_train, y=labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "tree.plot_tree(new_tree, feature_names=new_data_train.columns, class_names=['go', 'no-go'], filled=True, proportion=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_accuracy = new_tree.score(X=new_data_test, y=new_labels_test)\n",
    "print('mean accuracy: {}%'.format(mean_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(new_tree, X=new_data_test, y_true=new_labels_test, display_labels=['go', 'no-go'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-brunswick",
   "metadata": {},
   "source": [
    "# As an exercise, choose different features to drop and graph the decision tree's logic. Does anything happen to its logic?\n",
    "\n",
    "This function will also present your model's accuracy and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_not_these_features(features=['weather', 'external partners']):\n",
    "    temp_data_train = data_train.drop(columns=features)\n",
    "    temp_data_test = data_test.drop(columns=features)\n",
    "    the_tree = DecisionTreeClassifier(criterion='entropy', random_state=7)\n",
    "    the_tree.fit(X=temp_data_train, y=labels_train)\n",
    "    \n",
    "    # Plot Decision Tree's logic\n",
    "    plt.figure(figsize=(16,12))\n",
    "    tree.plot_tree(the_tree, feature_names=temp_data_train.columns, class_names=['go', 'no-go'], filled=True, proportion=True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print tree's accuracy\n",
    "    mean_accuracy = the_tree.score(X=temp_data_test, y=labels_test)\n",
    "    print('\\nmean accuracy: {}%\\n'.format(mean_accuracy * 100))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(the_tree, X=temp_data_test, y_true=labels_test, display_labels=['go', 'no-go'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_not_these_features(features=['weather'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-comparative",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-ballot",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-probe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-malpractice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-rabbit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
